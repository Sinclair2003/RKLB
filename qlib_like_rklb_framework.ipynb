{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Qlib-like RKLB Quant Research Notebook\n",
        "\n",
        "这个 notebook 复刻了经典 Qlib 研究流程：\n",
        "- Data Layer\n",
        "- Feature Layer\n",
        "- Model Layer\n",
        "- Strategy Layer\n",
        "- Backtest + Evaluation + Recorder\n",
        "\n",
        "默认读取 `market_data/rklb_daily.csv`。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "from dataclasses import dataclass\n",
        "from typing import Dict, List, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ===== 你主要改这里 =====\n",
        "@dataclass\n",
        "class FrameworkConfig:\n",
        "    csv_path: str = \"market_data/rklb_daily.csv\"\n",
        "    output_dir: str = \"outputs/rklb_qlib_like\"\n",
        "    horizon: int = 1\n",
        "    train_end: str = \"2023-12-31\"\n",
        "    valid_end: str = \"2024-12-31\"\n",
        "    test_end: str = \"2099-12-31\"\n",
        "    transaction_cost_bps: float = 5.0\n",
        "    annualization: int = 252\n",
        "    ridge_alpha: float = 5.0\n",
        "    threshold_grid: Tuple[float, ...] = (-0.005, -0.002, 0.0, 0.002, 0.005)\n",
        "\n",
        "cfg = FrameworkConfig()\n",
        "cfg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class DataHandlerCSV:\n",
        "    def __init__(self, csv_path: str):\n",
        "        self.csv_path = csv_path\n",
        "\n",
        "    def load(self) -> pd.DataFrame:\n",
        "        if not os.path.exists(self.csv_path):\n",
        "            raise FileNotFoundError(f\"CSV not found: {self.csv_path}\")\n",
        "\n",
        "        df = pd.read_csv(self.csv_path)\n",
        "        needed = {\"date\", \"open\", \"high\", \"low\", \"close\", \"volume\"}\n",
        "        missing = needed - set(df.columns)\n",
        "        if missing:\n",
        "            raise ValueError(f\"Missing columns: {sorted(missing)}\")\n",
        "\n",
        "        df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
        "        df = df.sort_values(\"date\").drop_duplicates(subset=[\"date\"], keep=\"first\")\n",
        "        df = df.set_index(\"date\")\n",
        "\n",
        "        numeric_cols = [\"open\", \"high\", \"low\", \"close\", \"volume\"]\n",
        "        for col in numeric_cols:\n",
        "            df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
        "\n",
        "        return df.dropna(subset=[\"close\"])\n",
        "\n",
        "\n",
        "class AlphaFeatureEngineer:\n",
        "    def __init__(self, horizon: int = 1):\n",
        "        self.horizon = horizon\n",
        "\n",
        "    @staticmethod\n",
        "    def _rsi(close: pd.Series, window: int = 14) -> pd.Series:\n",
        "        delta = close.diff()\n",
        "        up = delta.clip(lower=0)\n",
        "        down = -delta.clip(upper=0)\n",
        "        roll_up = up.ewm(alpha=1 / window, adjust=False).mean()\n",
        "        roll_down = down.ewm(alpha=1 / window, adjust=False).mean()\n",
        "        rs = roll_up / roll_down.replace(0, np.nan)\n",
        "        return 100 - (100 / (1 + rs))\n",
        "\n",
        "    @staticmethod\n",
        "    def _atr(df: pd.DataFrame, window: int = 14) -> pd.Series:\n",
        "        prev_close = df[\"close\"].shift(1)\n",
        "        tr = pd.concat(\n",
        "            [\n",
        "                (df[\"high\"] - df[\"low\"]).abs(),\n",
        "                (df[\"high\"] - prev_close).abs(),\n",
        "                (df[\"low\"] - prev_close).abs(),\n",
        "            ],\n",
        "            axis=1,\n",
        "        ).max(axis=1)\n",
        "        return tr.rolling(window).mean()\n",
        "\n",
        "    def transform(self, df: pd.DataFrame):\n",
        "        out = df.copy()\n",
        "        out[\"ret_1\"] = out[\"close\"].pct_change(1)\n",
        "        out[\"ret_5\"] = out[\"close\"].pct_change(5)\n",
        "        out[\"ret_10\"] = out[\"close\"].pct_change(10)\n",
        "        out[\"vol_5\"] = out[\"ret_1\"].rolling(5).std()\n",
        "        out[\"vol_20\"] = out[\"ret_1\"].rolling(20).std()\n",
        "\n",
        "        for win in (5, 10, 20, 60):\n",
        "            ma = out[\"close\"].rolling(win).mean()\n",
        "            out[f\"ma_ratio_{win}\"] = out[\"close\"] / ma - 1\n",
        "\n",
        "        out[\"rsi_14\"] = self._rsi(out[\"close\"], 14)\n",
        "        atr_14 = self._atr(out, 14)\n",
        "        out[\"atr_norm_14\"] = atr_14 / out[\"close\"].replace(0, np.nan)\n",
        "\n",
        "        log_vol = np.log1p(out[\"volume\"].clip(lower=0))\n",
        "        out[\"vol_z_20\"] = (log_vol - log_vol.rolling(20).mean()) / log_vol.rolling(20).std()\n",
        "\n",
        "        label_col = f\"label_ret_fwd_{self.horizon}d\"\n",
        "        out[label_col] = out[\"close\"].shift(-self.horizon) / out[\"close\"] - 1.0\n",
        "\n",
        "        feature_cols = [\n",
        "            \"ret_1\", \"ret_5\", \"ret_10\", \"vol_5\", \"vol_20\",\n",
        "            \"ma_ratio_5\", \"ma_ratio_10\", \"ma_ratio_20\", \"ma_ratio_60\",\n",
        "            \"rsi_14\", \"atr_norm_14\", \"vol_z_20\",\n",
        "        ]\n",
        "\n",
        "        out = out.replace([np.inf, -np.inf], np.nan)\n",
        "        out = out.dropna(subset=feature_cols + [label_col])\n",
        "        return out, feature_cols, label_col"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class RidgeReturnModel:\n",
        "    def __init__(self, alpha: float = 5.0):\n",
        "        self.alpha = alpha\n",
        "        self.weights = None\n",
        "\n",
        "    def fit(self, X: np.ndarray, y: np.ndarray) -> None:\n",
        "        ones = np.ones((X.shape[0], 1), dtype=float)\n",
        "        X_aug = np.hstack([ones, X])\n",
        "        reg = np.eye(X_aug.shape[1]) * self.alpha\n",
        "        reg[0, 0] = 0.0\n",
        "        self.weights = np.linalg.solve(X_aug.T @ X_aug + reg, X_aug.T @ y)\n",
        "\n",
        "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
        "        if self.weights is None:\n",
        "            raise RuntimeError(\"Model is not fitted\")\n",
        "        ones = np.ones((X.shape[0], 1), dtype=float)\n",
        "        X_aug = np.hstack([ones, X])\n",
        "        return X_aug @ self.weights\n",
        "\n",
        "\n",
        "class ThresholdLongOnlyStrategy:\n",
        "    def __init__(self, threshold: float = 0.0):\n",
        "        self.threshold = threshold\n",
        "\n",
        "    def generate_position(self, pred: pd.Series) -> pd.Series:\n",
        "        return (pred > self.threshold).astype(float)\n",
        "\n",
        "\n",
        "class Backtester:\n",
        "    def __init__(self, cost_bps: float = 5.0):\n",
        "        self.cost_rate = cost_bps / 10000.0\n",
        "\n",
        "    def run(self, df: pd.DataFrame, pred_col: str, label_col: str, threshold: float) -> pd.DataFrame:\n",
        "        out = df.copy()\n",
        "        strategy = ThresholdLongOnlyStrategy(threshold)\n",
        "        out[\"position\"] = strategy.generate_position(out[pred_col])\n",
        "        out[\"gross_ret\"] = out[\"position\"] * out[label_col]\n",
        "        turnover = (out[\"position\"] - out[\"position\"].shift(1).fillna(0)).abs()\n",
        "        out[\"cost\"] = turnover * self.cost_rate\n",
        "        out[\"strategy_ret\"] = out[\"gross_ret\"] - out[\"cost\"]\n",
        "        out[\"bench_ret\"] = out[label_col]\n",
        "        out[\"strategy_nav\"] = (1 + out[\"strategy_ret\"]).cumprod()\n",
        "        out[\"bench_nav\"] = (1 + out[\"bench_ret\"]).cumprod()\n",
        "        return out\n",
        "\n",
        "\n",
        "class Evaluator:\n",
        "    def __init__(self, annualization: int = 252):\n",
        "        self.annualization = annualization\n",
        "\n",
        "    @staticmethod\n",
        "    def _max_drawdown(nav: pd.Series) -> float:\n",
        "        peak = nav.cummax()\n",
        "        return float((nav / peak - 1.0).min())\n",
        "\n",
        "    def summarize(self, ret: pd.Series, nav: pd.Series) -> Dict[str, float]:\n",
        "        ret = ret.dropna()\n",
        "        if ret.empty:\n",
        "            return {\n",
        "                \"total_return\": 0.0,\n",
        "                \"annual_return\": 0.0,\n",
        "                \"annual_vol\": 0.0,\n",
        "                \"sharpe\": 0.0,\n",
        "                \"max_drawdown\": 0.0,\n",
        "                \"win_rate\": 0.0,\n",
        "            }\n",
        "\n",
        "        total_return = float(nav.iloc[-1] - 1.0)\n",
        "        ann_ret = float((1 + ret.mean()) ** self.annualization - 1)\n",
        "        ann_vol = float(ret.std(ddof=0) * np.sqrt(self.annualization))\n",
        "        sharpe = float(ann_ret / ann_vol) if ann_vol > 1e-12 else 0.0\n",
        "        mdd = self._max_drawdown(nav)\n",
        "        win_rate = float((ret > 0).mean())\n",
        "        return {\n",
        "            \"total_return\": total_return,\n",
        "            \"annual_return\": ann_ret,\n",
        "            \"annual_vol\": ann_vol,\n",
        "            \"sharpe\": sharpe,\n",
        "            \"max_drawdown\": mdd,\n",
        "            \"win_rate\": win_rate,\n",
        "        }\n",
        "\n",
        "    @staticmethod\n",
        "    def info_coef(pred: pd.Series, label: pd.Series) -> Dict[str, float]:\n",
        "        aligned = pd.concat([pred, label], axis=1).dropna()\n",
        "        if aligned.empty:\n",
        "            return {\"ic_pearson\": 0.0, \"ic_spearman\": 0.0}\n",
        "        p = aligned.iloc[:, 0]\n",
        "        y = aligned.iloc[:, 1]\n",
        "        p_rank = p.rank(method=\"average\")\n",
        "        y_rank = y.rank(method=\"average\")\n",
        "        return {\n",
        "            \"ic_pearson\": float(p.corr(y, method=\"pearson\")),\n",
        "            \"ic_spearman\": float(p_rank.corr(y_rank, method=\"pearson\")),\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Recorder:\n",
        "    def __init__(self, output_dir: str):\n",
        "        self.output_dir = output_dir\n",
        "        os.makedirs(self.output_dir, exist_ok=True)\n",
        "\n",
        "    def save_table(self, df: pd.DataFrame, name: str) -> str:\n",
        "        path = os.path.join(self.output_dir, name)\n",
        "        df.to_csv(path)\n",
        "        return path\n",
        "\n",
        "    def save_json(self, obj: Dict, name: str) -> str:\n",
        "        path = os.path.join(self.output_dir, name)\n",
        "        with open(path, \"w\", encoding=\"utf-8\") as f:\n",
        "            json.dump(obj, f, ensure_ascii=False, indent=2)\n",
        "        return path\n",
        "\n",
        "\n",
        "def split_by_time(df: pd.DataFrame, train_end: str, valid_end: str, test_end: str):\n",
        "    train_end_ts = pd.to_datetime(train_end)\n",
        "    valid_end_ts = pd.to_datetime(valid_end)\n",
        "    test_end_ts = pd.to_datetime(test_end)\n",
        "    train = df[df.index <= train_end_ts]\n",
        "    valid = df[(df.index > train_end_ts) & (df.index <= valid_end_ts)]\n",
        "    test = df[(df.index > valid_end_ts) & (df.index <= test_end_ts)]\n",
        "    return {\"train\": train, \"valid\": valid, \"test\": test}\n",
        "\n",
        "\n",
        "def tune_threshold(valid_df: pd.DataFrame, backtester: Backtester, evaluator: Evaluator, label_col: str, grid):\n",
        "    if valid_df.empty:\n",
        "        return 0.0\n",
        "    best_th = 0.0\n",
        "    best_sharpe = -np.inf\n",
        "    for th in grid:\n",
        "        bt = backtester.run(valid_df, pred_col=\"pred\", label_col=label_col, threshold=th)\n",
        "        m = evaluator.summarize(bt[\"strategy_ret\"], bt[\"strategy_nav\"])\n",
        "        if m[\"sharpe\"] > best_sharpe:\n",
        "            best_sharpe = m[\"sharpe\"]\n",
        "            best_th = th\n",
        "    return float(best_th)\n",
        "\n",
        "\n",
        "def run_pipeline(cfg: FrameworkConfig):\n",
        "    handler = DataHandlerCSV(cfg.csv_path)\n",
        "    feat = AlphaFeatureEngineer(horizon=cfg.horizon)\n",
        "    model = RidgeReturnModel(alpha=cfg.ridge_alpha)\n",
        "    backtester = Backtester(cost_bps=cfg.transaction_cost_bps)\n",
        "    evaluator = Evaluator(annualization=cfg.annualization)\n",
        "    recorder = Recorder(cfg.output_dir)\n",
        "\n",
        "    raw = handler.load()\n",
        "    data, features, label_col = feat.transform(raw)\n",
        "    splits = split_by_time(data, cfg.train_end, cfg.valid_end, cfg.test_end)\n",
        "\n",
        "    X_train = splits[\"train\"][features].to_numpy(dtype=float)\n",
        "    y_train = splits[\"train\"][label_col].to_numpy(dtype=float)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    for k in splits:\n",
        "        if splits[k].empty:\n",
        "            continue\n",
        "        X = splits[k][features].to_numpy(dtype=float)\n",
        "        splits[k] = splits[k].copy()\n",
        "        splits[k][\"pred\"] = model.predict(X)\n",
        "\n",
        "    threshold = tune_threshold(splits[\"valid\"], backtester, evaluator, label_col, cfg.threshold_grid)\n",
        "\n",
        "    metrics = {}\n",
        "    merged_bt = []\n",
        "    for split_name in (\"train\", \"valid\", \"test\"):\n",
        "        d = splits[split_name]\n",
        "        if d.empty:\n",
        "            metrics[split_name] = {}\n",
        "            continue\n",
        "        bt = backtester.run(d, pred_col=\"pred\", label_col=label_col, threshold=threshold)\n",
        "        merged_bt.append(bt.assign(split=split_name))\n",
        "        m = evaluator.summarize(bt[\"strategy_ret\"], bt[\"strategy_nav\"])\n",
        "        m.update(evaluator.info_coef(bt[\"pred\"], bt[label_col]))\n",
        "        m[\"threshold\"] = threshold\n",
        "        metrics[split_name] = m\n",
        "\n",
        "    all_bt = pd.concat(merged_bt, axis=0).sort_index() if merged_bt else pd.DataFrame()\n",
        "    if not all_bt.empty:\n",
        "        recorder.save_table(all_bt, \"backtest_detail.csv\")\n",
        "\n",
        "    recorder.save_json({\n",
        "        \"config\": cfg.__dict__,\n",
        "        \"feature_count\": len(features),\n",
        "        \"features\": features,\n",
        "        \"metrics\": metrics,\n",
        "    }, \"metrics.json\")\n",
        "\n",
        "    summary_rows = []\n",
        "    for split_name, vals in metrics.items():\n",
        "        if vals:\n",
        "            row = {\"split\": split_name}\n",
        "            row.update(vals)\n",
        "            summary_rows.append(row)\n",
        "    if summary_rows:\n",
        "        summary_df = pd.DataFrame(summary_rows)\n",
        "        recorder.save_table(summary_df, \"metrics_summary.csv\")\n",
        "    return metrics, all_bt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "metrics, backtest_df = run_pipeline(cfg)\n",
        "\n",
        "print(\"=\" * 72)\n",
        "print(\"Qlib-like notebook pipeline completed\")\n",
        "print(f\"Data: {cfg.csv_path}\")\n",
        "print(f\"Output: {os.path.abspath(cfg.output_dir)}\")\n",
        "print(\"=\" * 72)\n",
        "for split, m in metrics.items():\n",
        "    if not m:\n",
        "        print(f\"[{split}] empty\")\n",
        "    else:\n",
        "        print(\n",
        "            f\"[{split}] sharpe={m['sharpe']:.3f}, ann_ret={m['annual_return']:.2%}, \"\n",
        "            f\"mdd={m['max_drawdown']:.2%}, ic={m['ic_pearson']:.3f}, th={m['threshold']:.4f}\"\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "summary_path = os.path.join(cfg.output_dir, \"metrics_summary.csv\")\n",
        "detail_path = os.path.join(cfg.output_dir, \"backtest_detail.csv\")\n",
        "\n",
        "print(\"Summary file:\", summary_path)\n",
        "print(\"Detail file:\", detail_path)\n",
        "\n",
        "pd.read_csv(summary_path).round(4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 简单查看净值尾部\n",
        "if not backtest_df.empty:\n",
        "    backtest_df[[\"strategy_nav\", \"bench_nav\", \"split\"]].tail(20)\n",
        "else:\n",
        "    print(\"No backtest rows.\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}